{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from gptree import GPTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/ines/Documents/tese/tiny_gp'\n",
    "dataset = 'LD50'\n",
    "method = 'Double Tournament (Prob=1)'\n",
    "\n",
    "MAPPTING_METHODS = {\n",
    "    'StdGP': 'results_elitism/results',\n",
    "    'Double Tournament (Prob=1)': 'results_elitism/results_nested',\n",
    "    'Inverted Double Tournament (Prob=1)': 'results_elitism/results_inverted_tournament',\n",
    "    'Double Tournament (Prob=0.7)': 'results_elitism/results_nested_prob_0.7',\n",
    "    'Inverted Double Tournament (Prob=0.7)': 'results_elitism/results_inverted_nested_prob_0.7',\n",
    "    'Double Tournament (Prob=0.5)': 'results_elitism/results_nested_prob_0.5',\n",
    "    'Inverted Double Tournament (Prob=0.5)': 'results_elitism/results_inverted_nested_prob_0.5',\n",
    "    'MMOTS': 'results_elitism/mmots',\n",
    "    'Subsampled': 'results_elitism/results_nested_subsampled',\n",
    "    'Oversampled': 'results_elitism/results_nested_oversampled',\n",
    "    'DT_2_2': 'results_elitism/results_nested_2_2',\n",
    "    'DT_2_4': 'results_elitism/results_nested_2_4',\n",
    "    'DT_4_2': 'results_elitism/results_nested',\n",
    "    'DT_4_4': 'results_elitism/results_nested_4_4',\n",
    "    'DT_10_2': 'results_elitism/results_nested_10_2',\n",
    "    'DT_10_4': 'results_elitism/results_nested_10_4',\n",
    "    'Double Tournament Complexity Limit': 'results_elitism/results_nested_limit',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, lambdify, div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_division(a, b):\n",
    "    return div(a, b) if b != 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(x1, x2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminals = ['x1', 'x2']\n",
    "\n",
    "variables = symbols(\", \".join(terminals))\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<lambdifygenerated-19>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[26], line 3\u001b[0m\n    fn = lambdify(variables, expr, modules={\"custom_division\": custom_division})\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/tiny_gp/lib/python3.11/site-packages/sympy/utilities/lambdify.py:903\u001b[0;36m in \u001b[0;35mlambdify\u001b[0;36m\n\u001b[0;31m    c = compile(funcstr, filename, 'exec')\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<lambdifygenerated-19>:2\u001b[0;36m\u001b[0m\n\u001b[0;31m    return ( ( x1 + x2 ) + x1 ) custom_division x1\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "expr = '( ( x1 + x2 ) + x1 ) / x1'\n",
    "expr = expr.replace('/', 'custom_division')\n",
    "fn = lambdify(variables, expr, modules={\"custom_division\": custom_division})\n",
    "\n",
    "\n",
    "input = [1, 3]\n",
    "\n",
    "fn(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
      "       ...\n",
      "       'x617', 'x618', 'x619', 'x620', 'x621', 'x622', 'x623', 'x624', 'x625',\n",
      "       'x626'],\n",
      "      dtype='object', length=626)\n",
      "100    ((((((((x221) + (x453)) / ((x321) * (x518))) *...\n",
      "300    ((((((x558) / (x105)) * ((((x209) * (x249)) / ...\n",
      "500    ((((((x558) / (x105)) * ((((x453) + (x453)) / ...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18529/1896042223.py:23: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "<lambdifygenerated-8>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "<lambdifygenerated-8>:2: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "<lambdifygenerated-8>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar multiply\n",
      "\n",
      "<lambdifygenerated-9>:2: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "<lambdifygenerated-9>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "<lambdifygenerated-9>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar multiply\n",
      "\n",
      "<lambdifygenerated-9>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar add\n",
      "\n",
      "<lambdifygenerated-10>:2: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "<lambdifygenerated-10>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "<lambdifygenerated-10>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar multiply\n",
      "\n",
      "<lambdifygenerated-10>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar subtract\n",
      "\n",
      "<lambdifygenerated-10>:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar add\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GENS = [100, 300, 500]\n",
    "\n",
    "stdgp_path = base_path + f'/{MAPPTING_METHODS[\"StdGP\"]}/{dataset}/'\n",
    "method_path = base_path + f'/{MAPPTING_METHODS[method]}/{dataset}/'\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv(base_path + f'/data/{dataset}/train_1.csv', index_col=0)\n",
    "X = df.drop('Target', axis=1)\n",
    "Y = df['Target']\n",
    "\n",
    "terminals = X.columns\n",
    "print(terminals)\n",
    "\n",
    "# Read and plot function\n",
    "best_of_run = pd.read_csv(stdgp_path + 'best_in_run1.csv', index_col = 0)\n",
    "best_of_runs = best_of_run.iloc[0, GENS]\n",
    "print(best_of_runs)\n",
    "\n",
    "# Define symbols for the lambda functions\n",
    "variables = symbols(\", \".join(terminals))\n",
    "\n",
    "# Create lambdas using custom division\n",
    "tree_lambdas = [lambdify(variables, best_of_runs[i], modules={\"/\": custom_division}) for i in range(len(GENS))]\n",
    "\n",
    "outputs = [[], [], []]\n",
    "\n",
    "for idx, tree_lambda in enumerate(tree_lambdas):\n",
    "    for obs in X.values:\n",
    "        outputs[idx].append(tree_lambda(*obs))\n",
    "\n",
    "# Read and plot slopes\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3,\n",
    "                    subplot_titles=[f'Generation {gen}' for gen in GENS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"x1+ x2 / ((x1 - x2))\"\n",
    "\n",
    "terminals = ['x1', 'x2']\n",
    "\n",
    "def tokenize(s : str) -> list[str]:\n",
    "    tokens = []\n",
    "    lexeme = ''\n",
    "    for ch in s:\n",
    "        if ch == ' ':\n",
    "            if lexeme:\n",
    "                tokens.append(lexeme)\n",
    "                lexeme = ''\n",
    "            continue\n",
    "        elif not (ch.isalpha() or ch.isdigit()):\n",
    "            if lexeme:\n",
    "                tokens.append(lexeme)\n",
    "                lexeme = ''\n",
    "            tokens.append(ch)\n",
    "        else:\n",
    "            lexeme += ch\n",
    "    return tokens                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_operator(op: str) -> int:\n",
    "    from ops import add, sub, mul, div\n",
    "    match op:\n",
    "        case '+':\n",
    "            return (add, 1)\n",
    "        case '-':\n",
    "            return (sub, 1)\n",
    "        case '*':\n",
    "            return (mul, 2)\n",
    "        case '/':\n",
    "            return (div, 2)\n",
    "        case _:\n",
    "            return (None, 0)\n",
    "\n",
    "def parse(tokens: list[str], precedence= 0) -> GPTree:\n",
    "    lhs = parse_prefix(tokens)\n",
    "    while True:\n",
    "        if not tokens:\n",
    "            break\n",
    "        op, prec = parse_operator(tokens[0])\n",
    "        if op is None or prec < precedence:\n",
    "            break\n",
    "        tokens.pop(0)\n",
    "        lhs = GPTree(op, lhs, parse(tokens, prec), terminals=terminals)\n",
    "    return lhs\n",
    "\n",
    "def parse_prefix(tokens: list[str]) -> GPTree:\n",
    "    match tokens[0]:\n",
    "        case '(':\n",
    "            tokens.pop(0)\n",
    "            tree = parse(tokens, 0)\n",
    "            assert tokens.pop(0) == ')'\n",
    "            return tree\n",
    "        case _:\n",
    "            assert tokens[0].isidentifier()\n",
    "            return GPTree(tokens.pop(0), terminals=terminals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', '+', 'x2', '/', '(', '(', 'x1', '-', 'x2', ')', ')']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(source)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "   x1\n",
      "   div\n",
      "      x2\n",
      "      sub\n",
      "         x1\n",
      "         x2\n"
     ]
    }
   ],
   "source": [
    "gptree = parse(tokens)\n",
    "\n",
    "gptree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x1) + ((x2) / ((x1) - (x2)))'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptree.create_expression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gptree.create_lambda_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptree.compute_tree([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
      "       ...\n",
      "       'x617', 'x618', 'x619', 'x620', 'x621', 'x622', 'x623', 'x624', 'x625',\n",
      "       'x626'],\n",
      "      dtype='object', length=626)\n",
      "100    ((((((((x221) + (x453)) / ((x321) * (x518))) *...\n",
      "300    ((((((x558) / (x105)) * ((((x209) * (x249)) / ...\n",
      "500    ((((((x558) / (x105)) * ((((x453) + (x453)) / ...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18529/3246019915.py:23: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GENS = [100, 300, 500]\n",
    "\n",
    "stdgp_path = base_path + f'/{MAPPTING_METHODS[\"StdGP\"]}/{dataset}/'\n",
    "method_path = base_path + f'/{MAPPTING_METHODS[method]}/{dataset}/'\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv(base_path + f'/data/{dataset}/train_1.csv', index_col=0)\n",
    "X = df.drop('Target', axis=1)\n",
    "Y = df['Target']\n",
    "\n",
    "terminals = X.columns\n",
    "print(terminals)\n",
    "\n",
    "# Read and plot function\n",
    "best_of_run = pd.read_csv(stdgp_path + 'best_in_run1.csv', index_col = 0)\n",
    "best_of_runs = best_of_run.iloc[0, GENS]\n",
    "print(best_of_runs)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "# Define symbols for the lambda functions\n",
    "for idx, gen in enumerate(GENS):\n",
    "    tokens = tokenize(best_of_runs[idx])\n",
    "    gptree = parse(tokens)\n",
    "    gptree.create_lambda_function()\n",
    "    outputs.append([gptree.compute_tree(obs) for obs in X.values])\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3,\n",
    "                    subplot_titles=[f'Generation {gen}' for gen in GENS])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
